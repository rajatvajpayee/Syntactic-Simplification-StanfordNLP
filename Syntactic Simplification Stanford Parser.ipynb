{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9JQyI3cGLT7K"
   },
   "outputs": [],
   "source": [
    "# !wget http://nlp.stanford.edu/software/stanford-corenlp-full-2018-10-05.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 82
    },
    "colab_type": "code",
    "id": "fU8AkvFxLgQs",
    "outputId": "7b268a5c-9eb4-40cb-a6cd-c9b33a724119"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  stanford-corenlp-full-2018-10-05.zip\n",
      "replace stanford-corenlp-full-2018-10-05/jaxb-core-2.3.0.1-sources.jar? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
     ]
    }
   ],
   "source": [
    "!unzip stanford-corenlp-full-2018-10-05.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8B-WXBifL5ML"
   },
   "outputs": [],
   "source": [
    "# cd ./stanford-corenlp-full-2018-10-05/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x5P5e-iwdDT9"
   },
   "outputs": [],
   "source": [
    "!pip install stanfordcorenlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DmSFhpptdfXe"
   },
   "outputs": [],
   "source": [
    "# from stanfordcorenlp import StanfordCoreNLP\n",
    "# print('...')\n",
    "# nlp = StanfordCoreNLP(r'stanford-corenlp-full-2018-10-05')\n",
    "# print('...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ZOwXDundDMw"
   },
   "outputs": [],
   "source": [
    "# from stanfordcorenlp import StanfordCoreNLP\n",
    "# from time import time\n",
    "# start = time()\n",
    "# print('...')\n",
    "# nlp = StanfordCoreNLP(r'stanford-corenlp-full-2018-10-05')\n",
    "# print('...')\n",
    "\n",
    "# sentence = 'Do not drive faster if obstacles are closer than 5m'\n",
    "# print('Tokenize:', ['{}:{}'.format(i+1,x) for i,x in enumerate(nlp.word_tokenize(sentence))])\n",
    "# # print('Part of Speech:', nlp.pos_tag(sentence))\n",
    "# # print('Named Entities:', nlp.ner(sentence))\n",
    "# # print('Constituency Parsing:', nlp.parse(sentence))\n",
    "# print('Dependency Parsing:\\n', '\\n'.join([str(x) for x in nlp.dependency_parse(sentence) if x[0] not in rem_dep]))\n",
    "# print('Time Taken {}'.format(time() - start))\n",
    "# nlp.close() # Do not forget to close! The backend server wi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wvhrxf26YtzC"
   },
   "outputs": [],
   "source": [
    "props = {'annotators': 'coref', 'pipelineLanguage': 'en'}\n",
    "import json\n",
    "# text = 'Barack Obama was born in Hawaii.  He is the president. Obama was elected in 2008.'#'First vehicle is V1 which slows down it\\'s speed whenever V2 comes in range'\n",
    "# result = json.loads(nlp.annotate(text, properties=props))\n",
    "# num, mentions = list(result['corefs'].items())[0]\n",
    "# for mention in mentions:\n",
    "#     print(mention)\n",
    "# # result['corefs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1SNmrkR8fm52"
   },
   "outputs": [],
   "source": [
    "def coref_res(js):\n",
    "  temp = list(js.values())[0]\n",
    "  temp_ls = []\n",
    "  for x in temp:\n",
    "    temp_ls.append(x['text'])\n",
    "  return(temp_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ddh-GC5ar6zR"
   },
   "outputs": [],
   "source": [
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "from time import time\n",
    "start = time()\n",
    "print('Loading ....')\n",
    "nlp = StanfordCoreNLP(r'stanford-corenlp-full-2018-10-05')\n",
    "print('Loaded stanford model in {:.2f} seconds'.format(time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T09:07:17.375522Z",
     "start_time": "2020-05-26T09:07:17.201986Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Ib-T69zNdC-_"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dependencies' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-35b34ab4223b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mfind_tails\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdependencies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdependencies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mn_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdependencies\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmake_one\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dependencies' is not defined"
     ]
    }
   ],
   "source": [
    "def find_tails(number,dependencies = dependencies):\n",
    "    n_ = [[x[1],x[2]] for x in dependencies if x[1]==number]\n",
    "    return(n_)\n",
    "\n",
    "def make_one(ls):\n",
    "    temp = ls[0]\n",
    "    for y in ls[1:]:\n",
    "        temp.append(y[0])\n",
    "        temp.append(y[1])\n",
    "    return(temp) \n",
    "\n",
    "\n",
    "\n",
    "def sentence_former(tokens ,parsed ,rem_dep):\n",
    "    sentences = []\n",
    "    dependencies = [x for x in parsed if x[0] not in rem_dep]\n",
    "    pos_nsubjs = [[x[1],x[2]] for i,x in enumerate(dependencies) if x[0] == 'nsubj' or x[0] == 'nsubjpass']\n",
    "    for x in pos_nsubjs:\n",
    "        tail,head = x[0],x[1]\n",
    "        ls_1 = find_tails(x[0])\n",
    "        # print(ls_1)\n",
    "    if len(ls_1)!= 0:\n",
    "        ls_1 = make_one(ls_1)\n",
    "    \n",
    "    ls_2 = find_tails(x[1])\n",
    "    \n",
    "    if len(ls_2) != 0:\n",
    "        ls_2 = make_one(ls_2)\n",
    "      # print(ls_2)\n",
    "    if len(ls_1)!=0 and len(ls_2)==0:\n",
    "        n_ls_1 = sorted([y for y in {x for x in ls_1}])\n",
    "      # print(n_ls_1)\n",
    "        ds_1 = [tokens[int(i)-1] for i in n_ls_1]\n",
    "        sentences.append(' '.join(ds_1))\n",
    "      # print(' '.join(ds_1))\n",
    "    elif len(ls_2)!=0 and len(ls_1)==0:\n",
    "        n_ls_2 = sorted([y for y in {x for x in ls_2}])\n",
    "      # print(n_ls_2\n",
    "        ds_1 = [tokens[int(i)-1] for i in n_ls_2]\n",
    "      # print(' '.join(ds_1))\n",
    "        sentences.append(' '.join(ds_1))\n",
    "    elif len(ls_2)!=0 and len(ls_1)!=0:\n",
    "        for x in ls_2:\n",
    "            ls_1.append(x)\n",
    "      # print(ls_1)\n",
    "        ds_1 = [y for y in {x for x in ls_1}]\n",
    "        ds_1 = sorted(ds_1)\n",
    "      # print(ds_1)\n",
    "        ds_1 = [tokens[int(i)-1] for i in ds_1]\n",
    "        sentences.append(' '.join(ds_1))\n",
    "\n",
    "    temp = dependencies[0]\n",
    "    head_temp = temp[2]\n",
    "\n",
    "    N_tails_head = find_tails(head_temp)\n",
    "    nodes = make_one(N_tails_head)\n",
    "    nodes = sorted([y for y in {x for x in nodes}])\n",
    "    # print(nodes)\n",
    "    ds_1 = [tokens[int(i)-1] for i in nodes]\n",
    "    sentences.append(' '.join(ds_1))\n",
    "    # print(' '.join(ds_1))\n",
    "    new_sen = []\n",
    "    # cc = coref_res(result['corefs'])\n",
    "    # for x in sentences:\n",
    "    #   for y in coref_res(result['corefs']):\n",
    "    #     if y in x and x not in new_sen:\n",
    "    #       new_sen.append(x.replace(y,cc[0]))\n",
    "    #     elif x not in new_sen:\n",
    "    #       new_sen.append(x)\n",
    "    # sentences = new_sen\n",
    "    return(sentences)\n",
    "# print('Input sentence is :\\n{}'.format(sentence))\n",
    "# print('***********'*10)\n",
    "# print('Simpler sentences are :')\n",
    "# print('------------'*2)\n",
    "\n",
    "# # print('\\n'.join(['{} : {}'.format(i+1,x) for i,x in enumerate(tokens)]))\n",
    "# print('\\n'.join(sentence_former(tokens ,parsed ,rem_dep)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 157
    },
    "colab_type": "code",
    "id": "g4YrOMAqdDE1",
    "outputId": "4be14ed8-fe0f-4b90-d829-c96e52cde5d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 for default : 5\n",
      "Enter a text to check : Do not drive forward if object is closer than 5m\n",
      "---------------------------------------------------------------------------------------\n",
      "Original Sentence : \n",
      "Do not drive forward if object is closer than 5m\n",
      "---------------------------------------------------------------------------------------\n",
      "['object is closer 5m', 'Do not drive forward']\n",
      "Time Taken 0.13 sec\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import json\n",
    "\n",
    "\n",
    "# Show me the total inputs that a transformer can take if it worked on a single phase connection\n",
    "# sentences = ['Drive at most 6 kmph if obstacles closer than 20 m',\n",
    "# 'Do not drive forward if obstacles closer than 5 m ahead.',\n",
    "# 'Always drive at safe speed',\n",
    "# 'Eventually drive fast',\n",
    "# 'Eventually drive faster than 4 kpmh but slower than 10 kpmh.']\n",
    "intt = int(input('0 for default : '))\n",
    "if intt == 0:\n",
    "  sentence = 'Eventually drive faster than 4 kpmh but slower than 10 kpmh.'\n",
    "else: sentence = input('Enter a text to check : ')\n",
    "sentences = [sentence]\n",
    "start = time()\n",
    "for sentence in sentences:\n",
    "  print('-----------------------------'*3)\n",
    "  print('Original Sentence : \\n{}'.format(sentence))\n",
    "  print('-----------------------------'*3)\n",
    "  # sentence = 'On a racing track a vehicle can approach another vehicle with a maximum speed of 150kmph'\n",
    "  #'Barack Obama was born in Hawaii and he is the president who was elected in 2008.'#'A longitudinal distance between a vehicle VT1 that follows another vehicle VT2 where both are travelling in same direction is safe'\n",
    "  rem_dep = ['acl', 'appos', 'advcl', 'cc', 'ccomp', 'conj', 'dep', 'mark', 'parataxis','ref']\n",
    "  tokens = nlp.word_tokenize(sentence)\n",
    "  dep_parser = nlp.dependency_parse(sentence)\n",
    "  \n",
    "  text = sentence\n",
    "  result = json.loads(nlp.annotate(text, properties=props))\n",
    "  # print(result)\n",
    "  arr = [];\n",
    "\n",
    "  mentions = result['corefs']\n",
    "  # import pprint\n",
    "  # pprint.pprint(mentions.values())\n",
    "  # for x in list(mentions.values())[0]:\n",
    "  #   temp = x\n",
    "  #   arr.append(temp['text'])\n",
    "  # print(arr)\n",
    "\n",
    "  # print('\\n'.join(['{} : {}'.format(i+1,x) for i,x in enumerate(tokens)]))\n",
    "  simpli_sentences =sentence_former(tokens = tokens,parsed = dep_parser,rem_dep = rem_dep) \n",
    "  print(simpli_sentences)\n",
    "  # ff = []\n",
    "  # for x in simpli_sentences:\n",
    "  #   for y in arr:\n",
    "  #     if y in x:\n",
    "  #       temp = x.replace(y,arr[0])\n",
    "  #       ff.append(temp)\n",
    "  #     else:\n",
    "  #       ff.append(x)\n",
    "  # print(ff)D\n",
    "\n",
    "print('Time Taken {:.2f} sec'.format(time() - start))\n",
    "\n",
    "# print(dep_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "cpUHFAFSV-5z",
    "outputId": "3f0737c1-2411-4781-a94f-27e9d6c345dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dirve', 'faster', 'than', '5kmph', 'and', 'slower', 'than', '50kmph']\n",
      "[('ROOT', 0, 1), ('advmod', 1, 2), ('case', 4, 3), ('nmod', 2, 4), ('cc', 4, 5), ('conj', 4, 6), ('case', 8, 7), ('nmod', 4, 8)]\n"
     ]
    }
   ],
   "source": [
    "print(tokens)\n",
    "print(dep_parser)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "StanfordNLP",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
